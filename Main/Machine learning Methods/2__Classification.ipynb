{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using : KNN, SVM\n",
    "### Author: BELHADDAD Mohamed Islem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Charger les données d'entraînement/test à partir du fichier CSV\n",
    "train_data = pd.read_csv('Deep-Learning-models-for-ear-print-detection/data/train_test/ALBP/train_ALBP.csv')\n",
    "test_data = pd.read_csv('Deep-Learning-models-for-ear-print-detection/data/train_test/ALBP/test_ALBP.csv')\n",
    "print('Train:'+str(len(train_data))+' Test:'+str(len(test_data)))\n",
    "\n",
    "\n",
    "# Diviser les données d'entraînement en variables de caractéristiques (X_train) et variable cible (y_train)\n",
    "X_train =   train_data.iloc[:, :-1].values\n",
    "y_train =   train_data.iloc[:, -1].values\n",
    "\n",
    "y_train_discrete=y_train\n",
    "\n",
    "# Créer une instance de modèle SVM\n",
    "svm = SVC(kernel='linear', C=1, gamma='auto')\n",
    "\n",
    "# Entraîner le modèle SVM sur les données d'entraînement\n",
    "print(\"Training SVM Model...\")\n",
    "svm.fit(X_train, y_train_discrete)\n",
    "\n",
    "\n",
    "# Diviser les données de test en variables de caractéristiques (X_test) et variable cible (y_test)\n",
    "X_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data.iloc[:, -1].values\n",
    "\n",
    "# Seuiller y_test pour créer une variable cible discrète\n",
    "y_test_discrete = y_test\n",
    "\n",
    "# Prédire les étiquettes des données de test à l'aide du modèle entraîné\n",
    "y_pred = svm.predict(X_test)\n",
    "# # Calculer l'exactitude du modèle SVM sur les données de test\n",
    "accuracy = accuracy_score(y_test_discrete, y_pred)\n",
    "\n",
    "# Afficher l'exactitude du modèle SVM sur les données de test\n",
    "print(\"Exactitude du modèle SVM : {:.2f}%\".format(accuracy*100))\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(svm, 'svm_ALBP.pkl')\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "confusion = confusion_matrix(y_test,y_pred)\n",
    "fp =confusion.sum(axis =0)- np.diag(confusion)\n",
    "fn = confusion.sum(axis =1)- np.diag(confusion)\n",
    "tp =  np.diag(confusion)\n",
    "tn= confusion.sum()- (fp + fn + tp)\n",
    "\n",
    "# Calculter le taux d'erreur\n",
    "frr = fn /(tp + fn)\n",
    "far = fp / (tn + fp)\n",
    "eer = (frr + far) / 2\n",
    "print(\"Taux de faux rejet (FRR) : {:.2f}%\".format(frr.mean() * 100))\n",
    "print(\"Taux de fausse acceptation (FAR) : {:.2f}%\".format(far.mean() * 100))\n",
    "print(\"Taux d'erreur égal (EER) : {:.2f}%\".format(eer.mean() * 100))\n",
    "\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(30, 30))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap=\"Blues\")\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Diviser les données d'entraînement/test en variables de caractéristiques (X_train) et variable cible (y_train)\n",
    "train_data = pd.read_csv('data/train_test/ALBP/train_ALBP.csv')\n",
    "test_data = pd.read_csv('data/train_test/ALBP/test_ALBP.csv')\n",
    "print('Train:'+str(len(train_data))+' Test:'+str(len(test_data)))\n",
    "\n",
    "# Diviser les données d'entraînement en variables de caractéristiques (X_train) et variable cible (y_train)\n",
    "X_train =   train_data.iloc[:, :-1].values\n",
    "y_train =   train_data.iloc[:, -1].values\n",
    "\n",
    "# Créer une instance de modèle KNN avec k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Entraîner le modèle KNN sur les données d'entraînement\n",
    "print(\"Training KNN Model...\")\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "X_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data.iloc[:, -1].values\n",
    "\n",
    "# Prédire les étiquettes des données de test à l'aide du modèle entraîné\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(knn, 'knn_ALBP.pkl')\n",
    "\n",
    "# # Calculer l'exactitude du modèle KNN sur les données de test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#\n",
    "# # Afficher les mesures\n",
    "print(\"Exactitude du modèle KNN : {:.2f}%\".format(accuracy * 100))\n",
    "# print(\"FAR : {:.2f}%\".format(far * 100))\n",
    "# print(\"FRR : {:.2f}%\".format(frr * 100))\n",
    "# print(\"EER : {:.2f}%\".format(eer * 100))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
